<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>Nell | Temporal Smoothing for Efficient Uncertainty Estimation</title>
  <meta name="description" content="We show that temporal smoothing is an efficient method to estimate uncertainty in video stream processing.">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Temporal Smoothing for Efficient Uncertainty Estimation">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://blog.xxxnell.com/posts/temporal-smoothing">
  <meta property="og:description" content="We show that temporal smoothing is an efficient method to estimate uncertainty in video stream processing.">
  <meta property="og:site_name" content="Nell">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="https://blog.xxxnell.com/posts/temporal-smoothing">
  <meta name="twitter:title" content="Temporal Smoothing for Efficient Uncertainty Estimation">
  <meta name="twitter:description" content="We show that temporal smoothing is an efficient method to estimate uncertainty in video stream processing.">

  
    <meta property="og:image" content="https://blog.xxxnell.com/assets/og-image-7e87963071a58c8692d81dcb7623af35cae39dd5b847f8e5c5655ffc333defeb.jpg">
    <meta name="twitter:image" content="https://blog.xxxnell.com/assets/og-image-7e87963071a58c8692d81dcb7623af35cae39dd5b847f8e5c5655ffc333defeb.jpg">
  

  <link href="https://blog.xxxnell.com/feed.xml" type="application/rss+xml" rel="alternate" title="Nell Last 10 blog posts" />

  

  

    
      <link rel="icon" type="image/x-icon" href="/assets/favicon-light-a98c41efc5ed9fcc06ac664c9e2f7a9b3c3b2e0a52357d221fe382f6f4abc8fc.ico">
      <link rel="apple-touch-icon" href="/assets/apple-touch-icon-light-87d1f2a3a19b1500e5c1626a0492025ca5f7f97d24540dc5900288e92112925a.png">
      <link rel="stylesheet" type="text/css" href="/assets/light-bded5c6deb8bab3a79c4cd4d152b8637904863f012b575643ce274a559926ac5.css">
    

  

  <!-- MathJax -->
<!-- <script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script> -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: [
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    jax: ["input/TeX", "output/CommonHTML"],
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js",
      ]
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- utterances https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="xxxnell/blog"
        issue-number="10"
        crossorigin="anonymous"
        async>
</script>


  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90660277-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-90660277-1');
  </script>


<script src="/assets/vendor-0fb4b91f7ad6c193a69224eba7a01b691a2d7528ee672607575ccc0df3aea545.js" type="text/javascript"></script>


  <script src="/assets/webfonts-96493456d319d1bf419afdf8701552d4d486fee6afd304897d4fd81eb4e0cc0b.js" type="text/javascript"></script>



  <script src="/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js" type="text/javascript"></script>


<script src="/assets/application-5baeaec6ae90dfe28952c8193837fef2aee35ad61bcab5287466ddd6cc5b2c31.js" type="text/javascript"></script>




</head>

<body>
  <main>
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav scrollappear">
  <a href="/" class="header-logo" title="Nell">Nell</a>
  <ul class="header-links">
    
    
      <li>
        <a href="https://twitter.com/xxxnell" rel="noreferrer noopener" target="_blank" title="Twitter">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-twitter">
  <use href="/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter" xlink:href="/assets/twitter-8842c33965263ad1b03a978406826677a668f94125d5837e70ab83f24b3213a7.svg#icon-twitter"></use>
</svg>

        </a>
      </li>
    
    
    
    
      <li>
        <a href="https://github.com/xxxnell" rel="noreferrer noopener" target="_blank" title="GitHub">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-github">
  <use href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github" xlink:href="/assets/github-094f81040819f34343ee6ffff0980f17e2807b08b595eaaf66ae3554934fd78d.svg#icon-github"></use>
</svg>

        </a>
      </li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
      <li>
        <a href="mailto:xxxxxnell@gmail.com" title="Email">
          <svg xmlns="http://www.w3.org/2000/svg" class="icon-email">
  <use href="/assets/email-782473193bf750036fdb90e8daa075508a20509d01854c09f3237c144a3f0601.svg#icon-email" xlink:href="/assets/email-782473193bf750036fdb90e8daa075508a20509d01854c09f3237c144a3f0601.svg#icon-email"></use>
</svg>

        </a>
      </li>
    
    
    
  </ul>
</nav>



        <article class="article scrollappear">
          <header class="article-header">
            <h1>Temporal Smoothing for Efficient Uncertainty Estimation</h1>
            <p>We show that temporal smoothing is an efficient method to estimate uncertainty in video stream processing.</p>
            <div class="article-list-footer">
  <span class="article-list-date">
    January 31, 2021
  </span>
  <span class="article-list-divider">-</span>
  <span class="article-list-minutes">
    
    
      9 minute read
    
  </span>
  <span class="article-list-divider">-</span>
  <div class="article-list-tags">
    
      
      <a href="/tag/nn" title="See all posts with tag 'Deep Learning'">Deep Learning</a>
    
      
      <a href="/tag/bnn" title="See all posts with tag 'Bayesian Deep Learning'">Bayesian Deep Learning</a>
    
  </div>
</div>
          </header>

          <div class="article-content">
            <h2 id="tl-dr">TL; DR</h2>

<ul>
  <li>Bayesian neural networks (BNNs) predict not only predictive results but also uncertainties, so it is an effective method to build a trustworthy AI system. However, Bayesian neural network inference is significantly slow. To tackle this problem, we proposed a novel method called <em>vector quantized Bayesian neural network</em> (VQ-BNN) inference that uses previously memorized predictions.</li>
  <li>We propose <em>temporal smoothing</em> of predictions with exponentially decaying importance or <em>exponential moving average</em> by applying VQ-BNN to data streams.</li>
  <li>Temporal smoothing is an easy-to-implement method that performs significantly faster than BNNs while estimating predictive results comparable to or even superior to the results of BNNs.</li>
</ul>

<p>Translation: <a href="/ko/posts/temporal-smoothing">Korean</a></p>

<h2 id="recall-vector-quantized-bayesian-neural-network-improves-inference-speed-by-using-previously-memorized-predictions">Recall: vector quantized Bayesian neural network improves inference speed by using previously memorized predictions</h2>

<p>Bayesian neural networks (BNNs) predict not only predictive results but also uncertainties. However, in the previous post <a href="/posts/vqbnn">“Vector Quantized Bayesian Neural Network for Efficient Inference”</a>, we raised the problem that BNNs are significantly slower than traditional neural networks or deterministic NNs. To solve this problem, we also proposed vector quantized Bayesian neural network (VQ-BNN) that improves the inference speed by using previously memorized predictions.</p>

<p><a href="/assets/documentation/vqbnn/diagrams/bnn-inference-7b72acaa2319e76304aa387e92ed91eb413bfbf0629b6d6b99451ebe8276d5e6.png">
  <img src="/assets/documentation/vqbnn/diagrams/bnn-inference-7b72acaa2319e76304aa387e92ed91eb413bfbf0629b6d6b99451ebe8276d5e6.png" alt="bnn-inference" class="zooming" data-rjs="/assets/documentation/vqbnn/diagrams/bnn-inference-7b72acaa2319e76304aa387e92ed91eb413bfbf0629b6d6b99451ebe8276d5e6.png" data-zooming-width="" data-zooming-height="" />
</a></p>

<p>The figure above represents BNN inference. In short, BNN inference is Bayesian neural net ensemble average. BNN need iterative NN executions to predict a result for one data, and it gives raise to prohivitive comptuational cost.</p>

<p><a href="/assets/documentation/vqbnn/diagrams/vqbnn-inference-bddac8701dffd070e90b5d0bed117bff4f95ce4745c1bddd260869f4ff8524cd.png">
  <img src="/assets/documentation/vqbnn/diagrams/vqbnn-inference-bddac8701dffd070e90b5d0bed117bff4f95ce4745c1bddd260869f4ff8524cd.png" alt="vqbnn-inference" class="zooming" data-rjs="/assets/documentation/vqbnn/diagrams/vqbnn-inference-bddac8701dffd070e90b5d0bed117bff4f95ce4745c1bddd260869f4ff8524cd.png" data-zooming-width="" data-zooming-height="" />
</a></p>

<p>The figure above represents VQ-BNN inference. VQ-BNN inference makes a prediction for an input data <em>only once</em>, and compensates the predictive result with previously memorized predictions. Here, the importance is defined as the similarity between the observed and memorized data. VQ-BNN is an efficient method since it only needs one newly calculated prediction.</p>

<p>VQ-BNN inference needs <em>prototype</em> and <em>importance</em>. For computational efficiency, they have to meet the following requirements:</p>

<ol>
  <li><strong>Prototype</strong> should consist of proximate datasets.</li>
  <li><strong>Importance</strong> should be easy to calculate.</li>
</ol>

<p>Data stream analysis, especially video analysis, is an area where latency is important. Videos are large and video analysis sometimes requires real-time processing. Therefore, it is not practical to use BNN in this area because BNN inference is too slow. Instead, this post shows that VQ-BNN can process video streams easily and efficiently.</p>

<h2 id="real-world-data-streams-are-continuously-chaning">Real-world data streams are continuously chaning</h2>

<p>In order to use VQ-BNN as the approximation theory of BNN for data streams, we exploits the property that most real-world data streams change continuously. We call it <em>temporal consistency</em> or <em>temporal proximity</em> of data streams.</p>

<p><a href="/assets/documentation/temporal-smoothing/diagrams/consistency-515504b6fbda52d6dc7be3b78ecb5a488fafc0d2a260f648824e3be960c9f592.png">
  <img src="/assets/documentation/temporal-smoothing/diagrams/consistency-515504b6fbda52d6dc7be3b78ecb5a488fafc0d2a260f648824e3be960c9f592.png" alt="consistency" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/diagrams/consistency-515504b6fbda52d6dc7be3b78ecb5a488fafc0d2a260f648824e3be960c9f592.png" data-zooming-width="" data-zooming-height="" />
</a></p>

<p>The figure above shows an example of the temporal consistency of a video sequence. In this video stream, a car is moving slowly and continuously from right to left as timestamp <script type="math/tex">t</script> increases. Here, let the most recent frame <script type="math/tex">t=0</script> be the observed input data.</p>

<p>Thanks to this temporal consistency, we simply take <script type="math/tex">K</script> recent data as prototypes <script type="math/tex">\mathcal{S}</script>:</p>

<script type="math/tex; mode=display">\mathcal{S} = \{ \textbf{x}_t \vert 0 \geq t \geq -K \}</script>

<p>Similary, we propose an simple importance model which is defined as the similarity between the latest and memorized data. As shown below, it decreases exponentially over time:</p>

<script type="math/tex; mode=display">\pi(\textbf{x}_{t} \vert \mathcal{S}) = \frac{\exp(- t / \tau)}{\sum_{t=0}^{-K} \exp(- t / \tau)}</script>

<p>where hyperparameter <script type="math/tex">\tau</script> is decaying rate. The denominator is a normalizing constant for importance.</p>

<p>Taken together, VQ-BNN inference for data streams is just <em>temporal smoothing</em> or <em>exponential moving average</em> (EMA) of recent NN predictions <script type="math/tex">p(\textbf{y} \vert \textbf{x}_t, \textbf{w}_t)</script> at time <script type="math/tex">t</script>:</p>

<script type="math/tex; mode=display">p(\textbf{y} \vert \mathcal{S}, \mathcal{D}) \simeq  \sum_{t=0}^{-K} \alpha \exp(- t / \tau) \, p(\textbf{y} \vert \textbf{x}_t, \textbf{w}_t)</script>

<p>where <script type="math/tex">\alpha = \left({\sum_{t=0}^{-\infty} \exp(- t / \tau)} \right)^{-1}</script> is a normalizing constant.</p>

<p>In order to calculate VQ-BNN inference, we have to determine the prediction <script type="math/tex">p(\textbf{y} \vert \textbf{x}_t, \textbf{w}_t)</script> parameterized by NN. For classification tasks, we set <script type="math/tex">p(\textbf{y} \vert \textbf{x}_t, \textbf{w}_t)</script> as a categorical distribution parameterized by the <code class="highlighter-rouge">Softmax</code> of NN logit:</p>

<script type="math/tex; mode=display">p(\textbf{y} \vert \mathcal{S}, \mathcal{D}) \simeq \sum_{t=0}^{-K} \alpha \exp(- t / \tau) \, \texttt{Softmax}(\text{NN} (\textbf{x}_{t}, \textbf{w}_{t}))</script>

<p>where <script type="math/tex">\text{NN} (\textbf{x}_{t}, \textbf{w}_{t})</script> is NN logit, e.g. a prediction of NN with MC dropout layers, at time <script type="math/tex">t</script>.</p>

<!--
$$
p(\textbf{y} \vert \mathcal{S}, \mathcal{D}) \simeq  \sum_{t=0}^{-\infty} \alpha \exp(- t) \, p(\textbf{y} \vert \textbf{x}_t, \textbf{w}_t) 
$$

$$
p(\textbf{y} \vert \mathcal{S}, \mathcal{D}) = \alpha \, p(\textbf{y} \vert \textbf{x}_{0}, \textbf{w}_{0}) + (1 - \alpha) \, p_{-1}(\textbf{y} \vert \mathcal{S}, \mathcal{D})
$$
-->

<h2 id="temporal-smoothing-for-semantic-segmentation">Temporal smoothing for semantic segmentation</h2>

<p>We have previously shown that VQ-BNN for a data stream is a temporal smoothing of recent NN predictions. From now on, let’s apply VQ-BNN inference—i.e., temporal smoothing—to the real-world data streams. In this section, we use <a href="https://arxiv.org/abs/1506.02142">MC dropout</a> as a BNN approximation.</p>

<p><a href="/assets/documentation/temporal-smoothing/diagrams-bnn-5c298941986fc9b4cc3d77de7785ea2830896aab00e1300c372d720f14e52d86.gif">
  <img src="/assets/documentation/temporal-smoothing/diagrams-bnn-5c298941986fc9b4cc3d77de7785ea2830896aab00e1300c372d720f14e52d86.gif" alt="bnn-inference" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/diagrams-bnn-5c298941986fc9b4cc3d77de7785ea2830896aab00e1300c372d720f14e52d86.gif" data-zooming-width="" data-zooming-height="" />
</a></p>

<p>Let’s take an example of semantic segmentation, which is a pixel-wise classification, on real-world video sequence. MC dropout predicts the <code class="highlighter-rouge">Softmax</code> (not <code class="highlighter-rouge">Argmax</code>) probability multiple times for one video frame, and averages them. It generally requires 30 samples to achieve high predictive performance, so the inference speed is decreased by 30 times accordingly.</p>

<p>One more thing we would like to mention is that BNN is highly dependent on input data. The input frame can be an outlier, by motion blur or video defocus or anything else. When the input frame is noisy, BNN may give an erroneous result. In this example, the window of the car is a difficult part to classify. So, most predictions of BNN are incorrect results in this case.</p>

<p><a href="/assets/documentation/temporal-smoothing/diagrams-vqbnn-f2029d58795bb03d4af42a9a10a3fa5e6d54c00838ee41664070c132ffd25e6c.gif">
  <img src="/assets/documentation/temporal-smoothing/diagrams-vqbnn-f2029d58795bb03d4af42a9a10a3fa5e6d54c00838ee41664070c132ffd25e6c.gif" alt="vqbnn-inference" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/diagrams-vqbnn-f2029d58795bb03d4af42a9a10a3fa5e6d54c00838ee41664070c132ffd25e6c.gif" data-zooming-width="" data-zooming-height="" />
</a></p>

<p>In contrast, VQ-BNN predicts the result for the latest frame only once, and compensates it with previously memorized predictions. It is easy to memorize the sequence of NN predictions, so the computational performance of VQ-BNN is almost the same as that of deterministic NN.</p>

<p>Previously, we mentioned that BNN is overly dependent on input. What about VQ-BNN? In this example, the prediction for the most recent frame is incorrect. So far, it is the same as that of BNN. However, VQ-BNN smoothen the result by using past predictions, and past predictions classify the window of the car correctly. It implies that the results of VQ-BNN are robust to the noise of data such as motion blur.</p>

<h3 id="qualitative-results">Qualitative results</h3>

<div style="width:85%;margin:auto;">
  <a href="/assets/documentation/temporal-smoothing/diagrams/result-cacbc2bf811b833cd08f4ce99a6b63984a2ce94cf7c2ce3ada4148be6dc8bc3c.png">
  <img src="/assets/documentation/temporal-smoothing/diagrams/result-cacbc2bf811b833cd08f4ce99a6b63984a2ce94cf7c2ce3ada4148be6dc8bc3c.png" alt="semantic-segmentation-result" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/diagrams/result-cacbc2bf811b833cd08f4ce99a6b63984a2ce94cf7c2ce3ada4148be6dc8bc3c.png" data-zooming-width="" data-zooming-height="" />
</a>

</div>

<p>Let’s check the results. The second row shows the predictive results—i.e., <code class="highlighter-rouge">Argmax</code> of the predictive distributions—of BNN and VQ-BNN. As we expected, the result of BNN is incorrectly classified. In contrast, VQ-BNN gives a more accurate result than BNN.</p>

<p>The third row in this figure shows the predictive confidence—i.e., <code class="highlighter-rouge">Max</code> of the predictive distributions. The brighter the background, the higher confidence, that is the lower uncertainty. According to these confidences, VQ-BNN is less likely to be overconfident than BNN. This is because VQ-BNN uses both NN weight distribution and a data distribution <script type="math/tex">p(\textbf{x} \vert \mathcal{S})</script> at the same time.</p>

<div style="width:45%;margin:auto;">
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/input-seq1-ac10eccf9348855dc2496a2a927aff9fd787740e9c04986c15c1a70fcf65434b.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/input-seq1-ac10eccf9348855dc2496a2a927aff9fd787740e9c04986c15c1a70fcf65434b.gif" alt="input-seq" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/input-seq1-ac10eccf9348855dc2496a2a927aff9fd787740e9c04986c15c1a70fcf65434b.gif" data-zooming-width="240" data-zooming-height="180" />
</a>

</div>

<p>For a better understanding, let’s compare the predictive results of each method for the above video sequence. We use vanilla deterministic neural network (DNN) and BNN (MC dropout) as baselines. And we compare them to the temporal smoothing of DNN and BNN, called VQ-DNN and VQ-BNN respectively.</p>

<p><a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence-b943781bf0b1a982f52e756ea63e9a8fec266f10455e0c32878acef2bd0258ff.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence-b943781bf0b1a982f52e756ea63e9a8fec266f10455e0c32878acef2bd0258ff.gif" alt="vqbnn-unc-seq" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence-b943781bf0b1a982f52e756ea63e9a8fec266f10455e0c32878acef2bd0258ff.gif" data-zooming-width="1080" data-zooming-height="810" />
</a></p>

<!--
<table cellspacing="3" style="width:100%;text-align:center;">
  <tr>
    <th style="font-size:18px">DNN <div style="font-size:16px"></div></th>
    <th style="font-size:18px">VQ-DNN <div style="font-size:16px"></div></th>
    <th style="font-size:18px">BNN <div style="font-size:16px"></div></th>
    <th style="font-size:18px">VQ-BNN <div style="font-size:16px"></div></th>
  </tr>
  <tr>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-res-seq1-8575795ca10733de2bf284094fc18f891ba7b08491fa797142c4140e79bee5d7.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-res-seq1-8575795ca10733de2bf284094fc18f891ba7b08491fa797142c4140e79bee5d7.gif" alt="dnn-res-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-res-seq1-8575795ca10733de2bf284094fc18f891ba7b08491fa797142c4140e79bee5d7.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-res-seq1-64c383a1ba404f76a87a7bcd253b92c4beb54a2237ca45aa76854e4c966c6e88.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-res-seq1-64c383a1ba404f76a87a7bcd253b92c4beb54a2237ca45aa76854e4c966c6e88.gif" alt="vqdnn-res-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-res-seq1-64c383a1ba404f76a87a7bcd253b92c4beb54a2237ca45aa76854e4c966c6e88.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-res-seq1-999334db8b7b43ada4f923cc5405cc3909f79b2d2aee61bbbc6d98571fe7ec7f.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-res-seq1-999334db8b7b43ada4f923cc5405cc3909f79b2d2aee61bbbc6d98571fe7ec7f.gif" alt="bnn-res-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-res-seq1-999334db8b7b43ada4f923cc5405cc3909f79b2d2aee61bbbc6d98571fe7ec7f.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-res-seq1-42689973d263d63d80f4020ae9b564b1f94e95f947c719df85bb911f1261aaa9.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-res-seq1-42689973d263d63d80f4020ae9b564b1f94e95f947c719df85bb911f1261aaa9.gif" alt="vqbnn-res-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-res-seq1-42689973d263d63d80f4020ae9b564b1f94e95f947c719df85bb911f1261aaa9.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
  </tr>
  <tr>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-unc-seq1-1d1cf6431d5ca2b8e613dbb8931ea44649e359dc7e832961e52c114fc8a34fe4.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-unc-seq1-1d1cf6431d5ca2b8e613dbb8931ea44649e359dc7e832961e52c114fc8a34fe4.gif" alt="dnn-unc-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/dnn-unc-seq1-1d1cf6431d5ca2b8e613dbb8931ea44649e359dc7e832961e52c114fc8a34fe4.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-unc-seq1-7e21a4bd90f2db5aaea59efbd786a995de9bc1fecf68052c9918e5ee073a8990.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-unc-seq1-7e21a4bd90f2db5aaea59efbd786a995de9bc1fecf68052c9918e5ee073a8990.gif" alt="vqdnn-unc-seq1" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqdnn-unc-seq1-7e21a4bd90f2db5aaea59efbd786a995de9bc1fecf68052c9918e5ee073a8990.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-unc-seq1-17d805226fca398249bc1153260d989b793181a4cecbb5c611df0f113f16321e.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-unc-seq1-17d805226fca398249bc1153260d989b793181a4cecbb5c611df0f113f16321e.gif" alt="bnn-unc-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/bnn-unc-seq1-17d805226fca398249bc1153260d989b793181a4cecbb5c611df0f113f16321e.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
    <td>
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-unc-seq1-730a2181a6679291dec3719972612d4e9df8aeca0cbaed5d5447aa231ca4c4fd.gif">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-unc-seq1-730a2181a6679291dec3719972612d4e9df8aeca0cbaed5d5447aa231ca4c4fd.gif" alt="vqbnn-unc-seq" class="zooming"
    data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/sequence/vqbnn-unc-seq1-730a2181a6679291dec3719972612d4e9df8aeca0cbaed5d5447aa231ca4c4fd.gif"
    data-zooming-width="240"
    data-zooming-height="180"
  />
</a>

    </td>
  </tr>
</table> 
-->

<p>These are animations of predictive results. The first column is the results of deterministic NN and BNN, and the second column is their temporal smoothings.</p>

<p>In these videos, the predictive results of deterministic NN and BNN are <em>noisy</em>. Their classification results change irregularly and randomly. This phenomenon is widely observed not only in semantic segmentation, but also in image processing using deep learning. For example, in object detection, consider a case where the size of the bounding box changes discontinuously and sometimes disappears. In contrast, temporal smoothing of deterministic NN’s and BNN’s results are <em>stabilized</em>. They change smoothly. So, we might get more natural results by using temporal smoothing.</p>

<h3 id="quantitative-results">Quantitative results</h3>

<p>We previously mentioned that VQ-BNN may give a more accurate result than BNN, when the inputs are noisy. The quantitative results support the speculation.</p>

<style>
.styled-table {
    border-collapse: collapse;
    margin: 30px auto;
    font-size: 17x;
}

.styled-table thead tr {
    background-color: #009879;
    color: #ffffff;
    text-align: left;
}

.styled-table th,
.styled-table td {
    padding: 10px 1%;
}

.styled-table tbody tr:nth-of-type(even) {}

.styled-table tbody tr:first-of-type {
    border-top: 2px solid black;
    border-bottom: 1px solid black;
}

.styled-table tbody tr:last-of-type {
    border-bottom: 2px solid black;
}

.styled-table tbody tr.active-row {
    font-weight: bold;
    color: #009879;
}
</style>

<table cellspacing="3" style="width:90%;text-align:center;" class="styled-table">
  <tr>
    <th>Method</th>
    <th>Rel Thr<div>(%, ↑)</div></th>
    <th>NLL <div>(↓)</div></th>
    <th>Acc <div>(%, ↑)</div></th>
    <th>ECE <div>(%, ↓)</div></th>
  </tr>
  <tr>
    <td>DNN</td><td><b>100</b></td><td>0.314</td><td>91.1</td><td>4.31</td>
  </tr>
  <tr>
    <td>BNN</td><td>2.99</td><td>0.276</td><td>91.8</td><td>3.71</td>
  </tr>
  <tr>
    <td>VQ-DNN</td><td>98.2</td><td>0.284</td><td>91.2</td><td>3.00</td>
  </tr>
  <tr>
    <td>VQ-BNN</td><td>92.7</td><td><b>0.253</b></td><td><b>92.0</b></td><td><b>2.24</b></td>
  </tr>
</table>

<p>This table shows the performance of the methods with semantic segmentation task on the CamVid dataset. We use arrows to indicate which direction is better.</p>

<p>First of all, we measure relative throughput (<em>Rel Thr</em>), which is the relative number of video frames processed per second. In this experiment, we use MC dropout with 30 forward passes to predict results, so the throughput of BNN is only 1/30 of that of deterministic NN. In contrast, the inference speed of VQ-BNN is comparable to that of deterministic NN, and 30✕ higher than that of BNN.</p>

<p>We also measure a trio for this semantic segmentation task. One is a <em>NLL</em> which is a proper scoring rule, two is a global pixel accuracy (<em>Acc</em>), and the last one is an expected calibration error (<em>ECE</em>) to measure the uncertainty reliability. In terms of these metrics, the predictive performance of BNN is obviously better than that of deterministic NN. More important thing is, VQ-BNN predicts more accurate results than BNN. Similarly, the results of VQ-DNN show that temporal smoothing improves predictive performance even without using BNN.</p>

<p>When we use <a href="https://arxiv.org/abs/1612.01474">deep ensemble</a> instead of MC dropout, we obtain similar results. NLL of deep ensemble with 5 models is 0.216, and NLL of temporal smoothing with deep ensemble is 0.235 which is comparable to the result of the deep ensemble.</p>

<div style="width:85%;margin:auto;">
  <a href="/assets/documentation/temporal-smoothing/semantic-segmentation/reliability-diagram-extended-b9b0d294f908966be29e1e317755965dbe58f8f241511e2acd622f8859484c8a.png">
  <img src="/assets/documentation/temporal-smoothing/semantic-segmentation/reliability-diagram-extended-b9b0d294f908966be29e1e317755965dbe58f8f241511e2acd622f8859484c8a.png" alt="reliability-diagram" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/semantic-segmentation/reliability-diagram-extended-b9b0d294f908966be29e1e317755965dbe58f8f241511e2acd622f8859484c8a.png" data-zooming-width="" data-zooming-height="" />
</a>

</div>

<p>This reliability diagram also shows consistent results that temporal smoothing is an effective method to calibrate results. As shown in this figure, deterministic NN is miscalibrated. In contrast, VQ-BNN is better calibrated than deterministic NN, and surprisingly better than BNN. Likewise, VQ-DNN is better calibrated than deterministic NN and BNN.</p>

<p>In conclusion, <em>using knowledge from the previous time steps is useful</em> for improving predictive performance and estimating uncertainties. Temporal smoothing is an easy-to-implement method that significantly speeds up Bayesian NN inference without loss of accuracy.</p>

<h2 id="further-reading">Further reading</h2>

<ul>
  <li>This post is based on the paper <a href="https://arxiv.org/abs/1907.05911">“Vector Quantized Bayesian Neural Network Inference for Data Streams”</a>. For more detailed information on VQ-BNN, please refer to the paper. For the implementation of VQ-BNN, please refer to <a href="https://github.com/xxxnell/temporal-smoothing">GitHub</a>. If you find this post or the paper useful, please consider citing the paper. Please contact me with any comments or feedback.</li>
  <li>For more qualitative results of semantic segmentation, please refer to <a href="https://github.com/xxxnell/temporal-smoothing/blob/master/resources/README.md">GitHub</a>.</li>
  <li>We have shown that predictive performance can be further improved by using <em>future predictions</em>—as well as past predictions. For more detailed informations, please refer to Appendix D.1 and Figure 11 in the <a href="https://arxiv.org/abs/1907.05911">paper</a>.</li>
  <li>
    <p>The figure below shows an example of the results and uncertainties for each method with monochronic depth estimation task. In this example, we observe that the uncertainty represented by VQ-DNN differs from the uncertainty represented by BNN. VQ-BNN contains both types of uncertainties. For more detailed informations, please refer to Appendix D.2 in the <a href="https://arxiv.org/abs/1907.05911">paper</a>.</p>

    <p><a href="/assets/documentation/temporal-smoothing/depth-estimation/visualize/result-e6b3f7d710a7fdd371577b4ef55e51b83c4915f3d177cf59ae9ab29e159d7d9a.png">
<img src="/assets/documentation/temporal-smoothing/depth-estimation/visualize/result-e6b3f7d710a7fdd371577b4ef55e51b83c4915f3d177cf59ae9ab29e159d7d9a.png" alt="depth-estimation-result" class="zooming" data-rjs="/assets/documentation/temporal-smoothing/depth-estimation/visualize/result-e6b3f7d710a7fdd371577b4ef55e51b83c4915f3d177cf59ae9ab29e159d7d9a.png" data-zooming-width="" data-zooming-height="" />
</a></p>
  </li>
</ul>


          </div>
          <div class="article-share">
            
            
            <a href="https://twitter.com/home?status=Temporal+Smoothing+for+Efficient+Uncertainty+Estimation%20-%20https://blog.xxxnell.com/posts/temporal-smoothing%20by%20@xxxnell" title="Share on Twitter" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M492 109.5c-17.4 7.7-36 12.9-55.6 15.3 20-12 35.4-31 42.6-53.6 -18.7 11.1-39.4 19.2-61.5 23.5C399.8 75.8 374.6 64 346.8 64c-53.5 0-96.8 43.4-96.8 96.9 0 7.6 0.8 15 2.5 22.1 -80.5-4-151.9-42.6-199.6-101.3 -8.3 14.3-13.1 31-13.1 48.7 0 33.6 17.2 63.3 43.2 80.7C67 210.7 52 206.3 39 199c0 0.4 0 0.8 0 1.2 0 47 33.4 86.1 77.7 95 -8.1 2.2-16.7 3.4-25.5 3.4 -6.2 0-12.3-0.6-18.2-1.8 12.3 38.5 48.1 66.5 90.5 67.3 -33.1 26-74.9 41.5-120.3 41.5 -7.8 0-15.5-0.5-23.1-1.4C62.8 432 113.7 448 168.3 448 346.6 448 444 300.3 444 172.2c0-4.2-0.1-8.4-0.3-12.5C462.6 146 479 129 492 109.5z"/></svg>
            </a>
            <a href="https://www.facebook.com/sharer/sharer.php?u=https://blog.xxxnell.com/posts/temporal-smoothing" title="Share on Facebook" rel="noreferrer noopener" target="_blank">
              <svg viewBox="0 0 512 512"><path d="M288 192v-38.1c0-17.2 3.8-25.9 30.5-25.9H352V64h-55.9c-68.5 0-91.1 31.4-91.1 85.3V192h-45v64h45v192h83V256h56.4l7.6-64H288z"/></svg>
            </a>
          </div>

          

        </article>
        <footer class="footer scrollappear">
  <!--
  <p>
    About <a href="/about" title="About me">Nell</a>.
  </p>
  -->

  <div class="lang-sels">
    
      
      <div class="lang-sel" onclick="location.href='/posts/temporal-smoothing';" style="font-weight: bold;">en</div>
      <div class="lang-div">|</div>
    
      
      <div class="lang-sel" onclick="location.href='/ko/posts/temporal-smoothing';" >ko</div>
      <div class="lang-div">|</div>
    
  </div>

</footer>

      </div>
    </div>
  </main>
  <!-- MathJax -->
<!-- <script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script> -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: [
      "MathMenu.js",
      "MathZoom.js",
      "AssistiveMML.js",
      "a11y/accessibility-menu.js"
    ],
    jax: ["input/TeX", "output/CommonHTML"],
    TeX: {
      extensions: [
        "AMSmath.js",
        "AMSsymbols.js",
        "noErrors.js",
        "noUndefined.js",
      ]
    }
  });
</script>
<script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<!-- utterances https://utteranc.es/ -->
<script src="https://utteranc.es/client.js"
        repo="xxxnell/blog"
        issue-number="10"
        crossorigin="anonymous"
        async>
</script>


  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-90660277-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-90660277-1');
  </script>


<script src="/assets/vendor-0fb4b91f7ad6c193a69224eba7a01b691a2d7528ee672607575ccc0df3aea545.js" type="text/javascript"></script>


  <script src="/assets/webfonts-96493456d319d1bf419afdf8701552d4d486fee6afd304897d4fd81eb4e0cc0b.js" type="text/javascript"></script>



  <script src="/assets/scrollappear-e2da8ea567e418637e31266cc5302126eaa79f62a2273739086358b589a89ee6.js" type="text/javascript"></script>


<script src="/assets/application-5baeaec6ae90dfe28952c8193837fef2aee35ad61bcab5287466ddd6cc5b2c31.js" type="text/javascript"></script>



</body>
</html>
